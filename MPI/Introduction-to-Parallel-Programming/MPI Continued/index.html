

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="刘笑笑">
  <meta name="keywords" content="java、go、操作系统、网络">
  
    <meta name="description" content="第一节、Advanced communication in MPI一、Welcome to Week 4在本周，我们将介绍一些高级MPI主题，当你问自己如何做得更好时，你可能会发现这些主题很有用。一个更好的并行化方法是将计算和通信与非阻塞通信重叠起来。另一个问题是，我们是否可以用MPI和OpenMP减少内存，用混合或单边的方法获得速度？当事情变得很大时，我们希望把它们和我们自己的派生类型结合在一起">
<meta property="og:type" content="article">
<meta property="og:title" content="MPI Continued">
<meta property="og:url" content="http://by.ecel.top/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/index.html">
<meta property="og:site_name" content="Hello">
<meta property="og:description" content="第一节、Advanced communication in MPI一、Welcome to Week 4在本周，我们将介绍一些高级MPI主题，当你问自己如何做得更好时，你可能会发现这些主题很有用。一个更好的并行化方法是将计算和通信与非阻塞通信重叠起来。另一个问题是，我们是否可以用MPI和OpenMP减少内存，用混合或单边的方法获得速度？当事情变得很大时，我们希望把它们和我们自己的派生类型结合在一起">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://by.ecel.top/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/image-20221210105123759.png">
<meta property="og:image" content="http://by.ecel.top/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/image-20221210105331732.png">
<meta property="og:image" content="http://by.ecel.top/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/image-20221210105602570.png">
<meta property="og:image" content="http://by.ecel.top/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/image-20221210111905587.png">
<meta property="og:image" content="http://by.ecel.top/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/image-20221210112048211.png">
<meta property="og:image" content="http://by.ecel.top/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/image-20221210173514927.png">
<meta property="article:published_time" content="2022-12-10T02:32:47.000Z">
<meta property="article:modified_time" content="2022-12-10T15:42:10.142Z">
<meta property="article:author" content="刘笑笑">
<meta property="article:tag" content="并行计算">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://by.ecel.top/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/image-20221210105123759.png">
  
  
  
  <title>MPI Continued - Hello</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"by.ecel.top","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0,"license":"BY","author":{"enable":true},"post_date":{"enable":true,"format":"LL"},"update_date":{"enable":false,"format":"LL"}},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  



  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Liuxiaoxiao</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="MPI Continued"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-12-10 10:32" pubdate>
          2022年12月10日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          12k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          103 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">MPI Continued</h1>
            
              <p class="note note-info">
                
                  
                    本文最后更新于：2022年12月10日 晚上
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h2 id="第一节、Advanced-communication-in-MPI"><a href="#第一节、Advanced-communication-in-MPI" class="headerlink" title="第一节、Advanced communication in MPI"></a>第一节、<strong>Advanced communication in MPI</strong></h2><h3 id="一、Welcome-to-Week-4"><a href="#一、Welcome-to-Week-4" class="headerlink" title="一、Welcome to Week 4"></a>一、Welcome to Week 4</h3><p>在本周，我们将介绍一些高级MPI主题，当你问自己如何做得更好时，你可能会发现这些主题很有用。<br>一个更好的并行化方法是<strong>将计算和通信与非阻塞通信重叠</strong>起来。另一个问题是，我们是否可以<strong>用MPI和OpenMP减少内存，用混合或单边的方法获得速度</strong>？当事情变得很大时，我们希望把它们和我们自己的派生类型结合在一起，这样可以简化编程。在本周结束时，我们将研究一下文件的并行编写，可以用它来代替通过MPI收集结果。还有一些高级的MPI主题，我们不会在这里详细介绍，它们是其他PRACE课程的一部分。</p>
<h3 id="二、Non-Blocking-communications"><a href="#二、Non-Blocking-communications" class="headerlink" title="二、Non-Blocking communications"></a>二、Non-Blocking communications</h3><p>我们在上一周看到，MPI中的通信类型可以用两个参数来划分，即根据参与的进程数量来划分。</p>
<ul>
<li>点对点通信</li>
<li>集体通信</li>
</ul>
<p>而另一种划分方式则是与操作的完成情况有关，即。</p>
<ul>
<li>阻塞性操作</li>
<li>非阻塞性操作</li>
</ul>
<p>在我们之前学习的通信模式中，我们已经看到了一些问题，直到现在。例如，在环形的例子中，我们有一个循环分布的进程，我们想沿着环形发送消息，我们意识到，阻塞式例程在某种程度上不适合于此。问题是，对于第二个或第三个进程来说，为了真正接收到一些东西，它将不得不等待消息被发送到第一个进程，以此类推。所以，很明显，我们正在失去时间，而且没有产生一个好的并行应用。</p>
<img src="/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/image-20221210105123759.png" srcset="/img/loading.gif" lazyload alt="image-20221210105123759" style="zoom:50%;">

<p>在使用阻塞例程时，当我们对代码进行剖析时，经常会出现我们之前讨论过的死锁问题，也就是说，要么有一些已发送的数据我们从未收到，要么反之亦然。尽管这种情况可以解决，然而，还有一个更复杂的问题会出现。假设在前面的例子中，如果我们会使用阻塞式通信来做。在这种情况下，我们基本上会把我们的代码序列化（见下图），我们可以看到一些进程需要等待；我们的资源被浪费了。这就明确了需要一些其他的聪明的方法来通过这个环来发送消息，而不需要那么多的等待时间，这就是非阻塞通信发挥作用的地方了。</p>
<img src="/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/image-20221210105331732.png" srcset="/img/loading.gif" lazyload alt="image-20221210105331732" style="zoom:50%;">

<p>正如我们在上一周已经看到的，那个非阻塞例程立即返回，并允许子程序执行其他工作，所以我们可以在两者之间做一些工作，这很有用，因为，例如，我们可以发送一个消息，做一些操作，然后我们可以接收消息。所以，这三个部分在非阻塞式通信中是必不可少的。</p>
<p>所以，非阻塞式通信分为三个阶段。</p>
<ul>
<li>第一阶段显然是启动非阻塞通信。我们将用大写的I来区分所有非阻塞的命令，这意味着立即。因此，在MPI和下划线之后，将立即出现大写的I：MPI_Isend和MPI_Irecv。这些协议将看起来像。</li>
</ul>
<figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs objectivec"><span class="hljs-built_in">MPI_Isend</span> (<span class="hljs-type">void</span> *buf, <span class="hljs-type">int</span> count, <span class="hljs-built_in">MPI_Datatype</span> datatype, <span class="hljs-type">int</span> dest, <span class="hljs-type">int</span> tag, <span class="hljs-built_in">MPI_Comm</span> comm, <span class="hljs-built_in">MPI_Request</span> *request);<br></code></pre></td></tr></table></figure>

<p>​		and</p>
<figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs objectivec"><span class="hljs-built_in">MPI_Irecv</span> (<span class="hljs-type">void</span> *buf, <span class="hljs-type">int</span> count, <span class="hljs-built_in">MPI_Datatype</span> datatype, <span class="hljs-type">int</span> source, <span class="hljs-type">int</span> tag, <span class="hljs-built_in">MPI_Comm</span> comm, <span class="hljs-built_in">MPI_Request</span> *request);<br></code></pre></td></tr></table></figure>

<p> 然后我们可以做一些其他的工作，因为当我们使用这个例程的时候，它并没有阻挡我们，所以我们可以在这之后做一些操作。然而，稍后我们实际上要检查消息是否已经被收到。</p>
<p>为了完成这个最后阶段，我们需要等待非阻塞通信的完成，我们通过调用MPI_Wait函数来完成这个任务。这就完成了整个过程。这个请求只是MPI中类似于status的另一个结构，所以我们只是把它定义为类似于status，然后把指针放在那里。这个函数的原型看起来像。</p>
<figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs objectivec"><span class="hljs-built_in">MPI_Wait</span> (<span class="hljs-built_in">MPI_Request</span> *request, <span class="hljs-built_in">MPI_Status</span> *status);<br></code></pre></td></tr></table></figure>

<p>在下面两个例子的帮助下，我们将更清楚地理解这一点。</p>
<img src="/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/image-20221210105602570.png" srcset="/img/loading.gif" lazyload alt="image-20221210105602570" style="zoom:50%;">

<p>在这个例子中，我们假设所有的进程都想沿环路分享一些信息。如图所示，进程0想向1发送一些信息，6想向0发送一些信息，以此类推。这里的想法是，首先我们初始化非阻塞的发送，然后我们发送信息。所以，主要是我们启动非阻塞发送到右边的邻居。正如我们所知道的，在非阻塞通信中，在我们完成了这些之后，我们可以做一些工作。在我们的例子中，我们将通过经典的接收函数来接收消息。所以，在这个环形的例子中，接收来自左邻右舍的信息。最后，我们必须调用MPI_Wait函数，以检查一切是否已经完成，并使非阻塞性发送完成。</p>
<p>也许你已经清楚地看到，从根本上说，在这个环形的例子中，非阻塞性帮助了我们，所以每个进程都可以开始发送，但同时，我们仍然可以做其他事情。</p>
<p>以类似的方式，我们可以启动非阻塞的接收。所以在我们的环形例子中，这将意味着我们从左邻右舍发起非阻塞接收。这将意味着我们将收到一些东西，但也许不是现在，也许以后，我们做一些工作。在这种情况下，这将意味着向下面的接收者发送信息，因此，将信息发送给右边的邻居。最后，我们会调用MPI_Wait函数来等待非阻塞接收完成。<br>让我们在下面的练习中通过实现这些想法来进一步巩固这些想法吧</p>
<h3 id="三、Rotating-information-around-a-ring-non-blocking"><a href="#三、Rotating-information-around-a-ring-non-blocking" class="headerlink" title="三、Rotating information around a ring (non-blocking)"></a>三、Rotating information around a ring (non-blocking)</h3><p>在这个练习中，你将尝试使用阻塞式和非阻塞式通信。通过使用非阻塞通信，我们要避免闲置时间、死锁和序列化。这是两部分练习的第二部分。</p>
<p>这是之前环形通信练习的延续，当时你使用了阻塞通信来解决它。现在你将重复这个练习，但你现在要用非阻塞通信的最佳方式来解决死锁问题。</p>
<p>练习</p>
<ul>
<li>用MPI_Isend（非阻塞的同步发送）代替MPI_Send，并将等待语句放在正确的位置。保留正常阻塞的MPI_Recv。运行该程序。</li>
<li>你是否已经有了防止死锁的经验？你在过去使用过哪些方法？你有没有想过序列化的问题？</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs c">%%file ring.c<br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;mpi.h&gt;</span></span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span><br>&#123;<br>    <span class="hljs-type">int</span> rank, size;<br>    <span class="hljs-type">int</span> snd_buf, rcv_buf;<br>    <span class="hljs-type">int</span> right, left;<br>    <span class="hljs-type">int</span> sum, i;<br>    MPI_Status status;<br>    MPI_Request request; <span class="hljs-comment">//added request variable</span><br><br>    MPI_Init(<span class="hljs-literal">NULL</span>, <span class="hljs-literal">NULL</span>);<br>    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);<br>    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);<br><br>    right = (rank+<span class="hljs-number">1</span>)      % size;<br>    left  = (rank<span class="hljs-number">-1</span>+size) % size;<br><br>    sum = <span class="hljs-number">0</span>;<br>    snd_buf = rank;<br>    <span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>; i &lt; size; i++) <br>    &#123;<br>        MPI_Isend(&amp;snd_buf, <span class="hljs-number">1</span>, MPI_INT, right, <span class="hljs-number">17</span>, MPI_COMM_WORLD, &amp;request); <span class="hljs-comment">//substitute send with issend</span><br>        MPI_Recv(&amp;rcv_buf, <span class="hljs-number">1</span>, MPI_INT, left,  <span class="hljs-number">17</span>, MPI_COMM_WORLD, &amp;status);<br>        MPI_Wait(&amp;request, &amp;status); <span class="hljs-comment">//wait right after receive</span><br>        <span class="hljs-comment">//only after this wait you are allowed to modify the send buffer</span><br>        <span class="hljs-comment">//you must not modify the buffer between the issend and the wait</span><br>        snd_buf = rcv_buf;<br>        sum += rcv_buf;<br>    &#125;<br>    <span class="hljs-built_in">printf</span> (<span class="hljs-string">&quot;PE%i:\tSum = %i\n&quot;</span>, rank, sum);<br><br>    MPI_Finalize();<br>&#125;<br><br></code></pre></td></tr></table></figure>

<h3 id="四、One-sided-communication"><a href="#四、One-sided-communication" class="headerlink" title="四、One sided communication"></a>四、One sided communication</h3><p>正如我们在一开始已经学到的，MPI的并行化是基于分布式内存的。这意味着，如果我们在不同的核心上运行一个程序，每个核心都有自己的私有内存。由于内存对每个进程都是私有的，所以我们发送消息来从一个进程到另一个进程交换数据。</p>
<p>在两边（即点对点通信）和集体通信模型中，问题是（即使在非阻塞的情况下）发送方和接收方都必须明确参与数据交换操作，这就需要同步。</p>
<img src="/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/image-20221210111905587.png" srcset="/img/loading.gif" lazyload alt="image-20221210111905587" style="zoom:50%;">

<p>在这个例子中，我们可以看到，当我们有非阻塞程序时，但问题是，当我们调用MPI_Send，直到MPI_Recv收到消息时，有这么一段时间，两个进程都必须等待，它们不能做任何事情。因此，<strong>这种方法的一个重要缺点是，发送方必须等待接收方准备好接收数据，然后才能发送数据，或者反之亦然。这就造成了空闲时间。为了避免这种情况，我们使用单边通信。</strong></p>
<p>尽管MPI使用的是分布式内存方法，但MPI标准引入了<strong>远程内存访问（RMA）例程</strong>，也称为单边通信，因为它只需要一个进程来传输数据。<strong>简单地说，它使一个进程可以从其他进程的内存中访问一些数据。这个想法是，一个进程可以直接访问一个远程进程的内存地址空间，而无需该远程进程的干预。</strong></p>
<img src="/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/image-20221210112048211.png" srcset="/img/loading.gif" lazyload alt="image-20221210112048211" style="zoom:50%;">

<p>因此，<strong>我们不必明确调用参与通信的两个进程的发送和接收例程。一个进程可以直接从另一个进程的内存中放入和获取数据。这很有帮助，因为目标进程可以继续执行它的任务，做它的工作而不需要等待什么。</strong>因此，单边通信最重要的好处是，当一个进程从远程进程中放入或得到数据时，远程进程可以继续计算而不是等待数据。这减少了通信时间，并可以解决程序的可扩展性方面的一些问题（即在成千上万的MPI进程上）。</p>
<p><strong>为了允许其他进程访问其内存，一个进程必须明确地将自己的内存暴露给其他人。这意味着，为了让原进程访问目标进程的内存，目标进程必须允许该内存被访问和使用。它通过声明一个共享内存区域（也称为窗口）来做到这一点。</strong>这个窗口成为内存中的一个区域，它对通信器中的所有其他进程都是可用的，允许它们从其内存中放入和获取数据。这个窗口的创建是通过调用函数</p>
<figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs objectivec"><span class="hljs-built_in">MPI_Win_create</span> (<span class="hljs-type">void</span> *base, <span class="hljs-built_in">MPI_Aint</span> size, <span class="hljs-type">int</span> disp_unit, <span class="hljs-built_in">MPI_Info</span> info, <span class="hljs-built_in">MPI_Comm</span> comm, <span class="hljs-built_in">MPI_Win</span> *win);<br></code></pre></td></tr></table></figure>

<p>这个函数中的参数是相当不同的。它们是如下的。</p>
<ul>
<li>base是指向要公开的本地数据的指针，也就是我们想要访问的数据。</li>
<li>size表示本地数据的大小，单位是字节。</li>
<li>disp_unit是单位大小的位移。</li>
<li>info是信息参数。大多数情况下我们使用info_NULL。</li>
<li>comm是我们在前面所有函数中知道的通信器。</li>
<li>win代表窗口对象。</li>
</ul>
<p>在MPI应用的最后，我们必须用函数释放这个窗口</p>
<figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs objectivec"><span class="hljs-built_in">MPI_Win_free</span> (<span class="hljs-built_in">MPI_Win</span> *win);<br></code></pre></td></tr></table></figure>

<p>因此，通过这些函数，我们在内存周围创建了一个窗口，可以让其他人访问。这就是为什么在最后我们必须调用Win_free函数来释放这个窗口。</p>
<p>为了更好地理解，我们来看看一个经典的例子。</p>
<figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs objectivec"><span class="hljs-built_in">MPI_Win</span> win;<br><span class="hljs-type">int</span> shared_buffer[NUM_ELEMENTS];<br><span class="hljs-built_in">MPI_Win_create</span>(shared_buffer, NUM_ELEMENT, <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">int</span>), <span class="hljs-built_in">MPI_INFO_NULL</span>, <span class="hljs-built_in">MPI_COMM_WORLD</span>, &amp;win);<br>...<br><span class="hljs-built_in">MPI_Win_free</span>(&amp;win);<br></code></pre></td></tr></table></figure>

<p>所以在这里我们定义一个MPI结构变量win。然后我们通过动态分配或类似的方法定义一些数据或存储。利用这个缓冲区，我们实际上创建了窗口。所以在MPI_Win_create中，你可以看到我们想分享这个shared_buffer缓冲区。这里的大小是NUM_ELEMENTS。因为每个数据类型都是int，所以位移变成了，比方说可能是4字节宽。信息参数通常为NULL，通信器一如既往地是MPI_COMM_WORLD。一旦这个被调用，这个共享缓冲区就可以通过调用MPI_Put和MPI_Get例程被所有进程共享。当然，在应用程序结束时，我们要释放win窗口。</p>
<h4 id="MPI-Put-and-MPI-Get"><a href="#MPI-Put-and-MPI-Get" class="headerlink" title="MPI_Put and MPI_Get"></a><code>MPI_Put</code> and <code>MPI_Get</code></h4><p>为了访问这些数据，我们需要前面谈到的两个例程，即MPI_Put和MPI_Get。MPI_Put操作相当于起源进程的发送和目标进程的匹配接收。让我们来看看这些函数的原型，它们有相当多的参数。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">MPI_Put (<span class="hljs-type">void</span> *origin_addr, <span class="hljs-type">int</span> origin_count, MPI_Datatype origin_datatype, <span class="hljs-type">int</span> target_rank, MPI_Aint target_disp, <span class="hljs-type">int</span> target_count, MPI_Datatype_target_datatype, MPI_Win win)<br></code></pre></td></tr></table></figure>

<p>以同样的方式，MPI_Get与put操作类似，只是数据从目标内存转移到了源进程。这个函数的原型看起来像这样</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">MPI_Get (<span class="hljs-type">void</span> *origin_addr, <span class="hljs-type">int</span> origin_count, MPI_Datatype origin_datatype, <span class="hljs-type">int</span> target_rank, MPI_Aint target_disp, <span class="hljs-type">int</span> target_count, MPI_Datatype_target_datatype, MPI_Win win);<br></code></pre></td></tr></table></figure>

<p>我们将在下面的练习中深入了解这些函数的参数。但在这之前，我们需要讨论的另一件重要事情是同步。如果你还记得，我们在第二周学习OpenMP的概念时简要地讨论了这个概念。在MPI的单边通信中，目标进程调用函数来创建窗口，以便将其内存访问权交给其他进程。然而，在有多个用户的情况下，如果这些用户试图同时访问这些数据，就会导致一些问题，这一点已经非常明显。例如，假设有两个用户使用MPI_Put函数访问窗口来放置数据。这显然是一个需要避免的竞赛条件。这就是同步化发挥作用的地方。因此，为了避免在每个单边通信函数，即MPI_Get和MPI_Put之前和之后出现这种情况，我们需要使用函数</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">MPI_Win_fence (<span class="hljs-number">0</span>, MPI_Win win);<br></code></pre></td></tr></table></figure>

<p>这个函数实际上帮助我们同步数据，如果多个进程想访问同一个窗口，它将确保它们按顺序进行。因此，程序将允许不同的进程访问该窗口，但它将确保它不会同时发生。因此，重要的是，单边函数调用被这个栅栏函数所包围。</p>
<h3 id="五、One-sided-communication-in-a-ring"><a href="#五、One-sided-communication-in-a-ring" class="headerlink" title="五、One-sided communication in a ring"></a>五、One-sided communication in a ring</h3><p>你已经熟悉了环状通信。在这个练习中，目标是用单边通信代替非阻塞通信。</p>
<p>我们想通过使用MPI_Put或MPI_Get来替代对发送和接收例程的调用。所以我们有两个选择。</p>
<ol>
<li>之前调用send的进程，现在调用MPI_Put。发送缓冲区是一个本地缓冲区，接收缓冲区必须是一个窗口。</li>
<li>之前调用接收的进程，现在调用MPI_Get。发送缓冲区是一个窗口，接收缓冲区是一个本地缓冲区。</li>
</ol>
<p>在这个练习中，你将使用1.选项。所以你需要做的是为接收缓冲区创建一个窗口，并通过在先前调用MPI_Send的进程中调用MPI_Put来替代发送和接收。同时不要忘记用MPI_Win_fence进行同步。</p>
<h4 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h4><p>进入练习，填写骨架，在其进程中创建所有rcv_buf作为窗口。</p>
<p>用Win_fence&#x2F;Put&#x2F;Win_fence序列代替Isend&#x2F;Irecv&#x2F;Wait。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs c">%%file ring.c<br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;mpi.h&gt;</span></span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span><br>&#123;<br>    <span class="hljs-type">int</span> rank, size;<br>    <span class="hljs-type">int</span> snd_buf, rcv_buf;<br>    <span class="hljs-type">int</span> right, left;<br>    <span class="hljs-type">int</span> sum, i;<br><br>    MPI_Win win;<br><br>    MPI_Init(<span class="hljs-literal">NULL</span>, <span class="hljs-literal">NULL</span>);<br>    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);<br>    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);<br><br>    right = (rank+<span class="hljs-number">1</span>)      % size;<br>    left  = (rank<span class="hljs-number">-1</span>+size) % size;<br><br>    <span class="hljs-comment">/* Create the window. */</span><br>    MPI_Win_create(&amp;rcv_buf, (MPI_Aint) <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">int</span>), <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">int</span>), MPI_INFO_NULL, MPI_COMM_WORLD, &amp;win);<br><br>    sum = <span class="hljs-number">0</span>;<br>    snd_buf = rank;<br><br>    <span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>; i &lt; size; i++) <br>    &#123;<br>        MPI_Win_fence(MPI_MODE_NOSTORE | MPI_MODE_NOPRECEDE, win);<br>        MPI_Put(&amp;snd_buf, <span class="hljs-number">1</span>, MPI_INT, right, (MPI_Aint) <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, MPI_INT, win);<br>        MPI_Win_fence(MPI_MODE_NOSTORE | MPI_MODE_NOPUT | MPI_MODE_NOSUCCEED, win);<br><br>        snd_buf = rcv_buf;<br>        sum += rcv_buf;<br>    &#125;<br><br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;PE%i:\tSum = %i\n&quot;</span>, rank, sum);<br><br>    MPI_Win_free(&amp;win);<br><br>    MPI_Finalize();<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="六、Quiz：Do-you-understand-advanced-communication-in-MPI"><a href="#六、Quiz：Do-you-understand-advanced-communication-in-MPI" class="headerlink" title="六、Quiz：Do you understand advanced communication in MPI?"></a>六、Quiz：Do you understand advanced communication in MPI?</h3><ul>
<li><strong>在调用MPI_Win_create时，用什么单位来定义窗口的大小？</strong></li>
</ul>
<p>​		字节✅</p>
<p>​		由MPI_Datatype参数指定的单位❌</p>
<p>​		字节❌</p>
<ul>
<li><p>从MPI_Put调用返回后，立即覆盖包含发送数据的缓冲区是安全的。</p>
<p>真❌</p>
<p>错✅</p>
</li>
</ul>
<h2 id="第二节、MPI-OpenMP"><a href="#第二节、MPI-OpenMP" class="headerlink" title="第二节、MPI + OpenMP"></a>第二节、MPI + OpenMP</h2><h3 id="一、MPI-threading-methods"><a href="#一、MPI-threading-methods" class="headerlink" title="一、MPI + threading methods"></a>一、MPI + threading methods</h3><p>在本小节中，我们将在前两周对OpenMP进行介绍的基础上，看看如何将其纳入MPI。我们需要讨论这个问题的原因有很多，但最重要的是在高性能计算（HPC）中，计算机系统具有分层的硬件设计。因此，我们需要讨论如何有效地协调通过网络连接的多核节点的工作。我们还将看到每种方法的瓶颈所在。</p>
<p>在这个小节中，我们还将<strong>讨论或试图找出混合代码是否比MPI代码表现更好，并看看它与通信优势是否结果线程开销等有什么关系。</strong>最后，我们也会问自己，MPI方法是否是最好的方法，是否有其他的方法可以提供不同的速度或在节点内更有效的分层。我们将看到其他方法如何提供工作负载平衡，当我们处理在许多核心上运行的大型程序时，这种平衡就变得可操作了。为了了解我们将需要多少努力，确保所有的CPU都以最大的效率（100%）被利用，也就是说，没有睡眠的处理器，或睡眠的GPU，或睡眠的线程是可用的，这样所有的东西都被利用了。这将为我们提供机会，探索是否有一些其他可能的方法来更容易地解决这些问题，并以更有效的方式完成工作，例如使用一些其他语言等。</p>
<p>这是我们对并行编程的介绍，也就是说，我们只是在简单的MPI加线程方法的基础上进行学习。</p>
<p>为了举例说明，让我们将IBM Power8处理器与英特尔或AMD，即经典的x64架构进行比较。<strong>我们看到，Power8处理器每个核心有更多的线程。因此，与我们在笔记本电脑上发现的通常的超线程不同，我们通常在核心之外还有一个线程；在Power8处理器上，例如在一个插座上有八个处理核心，那么我们可以在每个核心上运行额外的八个线程，这样它们就可以共享高速缓存。</strong>如果我们运行的是OpenMP程序，用许多线程运行会提高性能。这意味着程序和线程共享变量、内存等。希望在我们最初的OpenMP课程中，在前两周的课程中，要做到这一点是非常简单的。</p>
<h4 id="MPI-OpenMP"><a href="#MPI-OpenMP" class="headerlink" title="MPI + OpenMP"></a>MPI + OpenMP</h4><p>我们可以尝试的两个主要线程范式是。</p>
<ul>
<li>MPI + OpenMP</li>
<li>MPI + MPI-3 shared memory</li>
</ul>
<p><strong>MPI+OpenMP对于非均匀内存架构来说通常是一种更好的方法，而且在我们有许多套接字的情况下，也就是缓存一致的非均匀内存。可以通过这样的方式进行优化，即我们只利用少量的MPI线程，其余的是OpenMP。</strong>像往常一样，先决条件是库必须对C来说是线程安全的，这并不复杂，因为C本身利用了很多内部变量，这些变量是在计算附近分配的，所以堆栈或附近的堆。在上一周，我们已经介绍了MPI，我们已经看到MPI有很多不同的消息传递程序。所以，MPI的方法是提供从简单到扩展的所有通信手段。OpenMP，或者说它的线程模型，是和MPI-2一起引入的，这样我们就可以在MPI-2中使用一些线程。从该库中，我们通常使用OpenMPI，但也有一些其他厂商特定的MPI库，特别是如果你从知名厂商那里购买的话。有一些经过调整的MPI库在你购买的集群上工作得最好，这意味着它考虑到了拓扑结构、延迟和MPI库本身的所有架构差异。</p>
<p>因此，在C语言中，有三个库是我们最初可以查询的。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">MPI_Init_thread</span> <span class="hljs-params">(<span class="hljs-type">int</span> * argc, <span class="hljs-type">char</span> ** argv[], <span class="hljs-type">int</span> thread_level_required,</span><br><span class="hljs-params">                    <span class="hljs-type">int</span> * thread_level_provided)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">MPI_Query_thread</span> <span class="hljs-params">(<span class="hljs-type">int</span> * thread_level_provided)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">MPI_Is_main_thread</span> <span class="hljs-params">(<span class="hljs-type">int</span> * flag)</span>;<br></code></pre></td></tr></table></figure>

<p>然而，在这之前，我们需要某些值，以提及我们可以从中获得的线程类型，或者说是线程的级别。因此，所需的值是，例如。</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">MPI_THREAD_SINGLE</span><br></code></pre></td></tr></table></figure>

<ul>
<li>这里只有一个线程将执行MPI调用。</li>
</ul>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">MPI_THREAD_FUNNELED</span><br></code></pre></td></tr></table></figure>

<ul>
<li>这里只有主线程会进行MPI调用。</li>
</ul>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">MPI_THREAD_SERIALIZED</span><br></code></pre></td></tr></table></figure>

<ul>
<li>在这种情况下，多个线程可以进行MPI调用，但一次只能调用一个。</li>
</ul>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">MPI_THREAD_MULTIPLE</span><br></code></pre></td></tr></table></figure>

<ul>
<li>这里多个线程可以调用MPI，没有任何限制。</li>
</ul>
<h3 id="二、Calculate-Pi-Using-MPI-THREAD-FUNNELED"><a href="#二、Calculate-Pi-Using-MPI-THREAD-FUNNELED" class="headerlink" title="二、Calculate Pi! Using MPI_THREAD_FUNNELED"></a>二、Calculate Pi! Using MPI_THREAD_FUNNELED</h3><p>使用线程的最安全和最简单的方法是使用MPI_THREAD_FUNNELED。这个级别的线程安全保证了多线程，但是只有主线程进行MPI调用（调用MPI_Init_thread的那个）。所有的MPI调用都是由主线程进行的，在OpenMP并行区域外或OpenMP主区域内。</p>
<p>本例笔记本显示了如何通过解决这个积分近似来计算Pi的值。</p>
<img src="/MPI/Introduction-to-Parallel-Programming/MPI%20Continued/image-20221210173514927.png" srcset="/img/loading.gif" lazyload alt="image-20221210173514927" style="zoom:50%;">

<p>在前几周，你已经用OpenMP和MPI进行了计算。我们将在这个例子中使用这两种方法。我们的目标是尽量少用MPI进行节点间的通信，在节点内部用OpenMP的共享内存计算来完成一切。完整的代码如下所示。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;omp.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;mpi.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> N 1000000</span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> *argv[])</span><br>&#123;<br>  <span class="hljs-type">int</span> rank;<br>  <span class="hljs-type">int</span> size;<br>  <span class="hljs-type">int</span> provided;<br>  <span class="hljs-type">double</span> subsum = <span class="hljs-number">0.0</span>;<br><br>  MPI_Init_thread(&amp;argc, &amp;argv, MPI_THREAD_FUNNELED, &amp;provided);<br>  MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);<br>  MPI_Comm_size(MPI_COMM_WORLD, &amp;size);<br>  <span class="hljs-type">int</span> nthreads = <span class="hljs-number">2</span>;<br>  omp_set_num_threads(nthreads);<br>  <br>  <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp parallel</span><br>  &#123;  <br>    <span class="hljs-type">int</span> tid = omp_get_thread_num();<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Thread %d within rank %d started.\n&quot;</span>, tid, rank);<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp for reduction(+:subsum)</span><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = rank; i &lt; N; i += size*nthreads)<br>      &#123;<br>        <span class="hljs-type">double</span> x = (i+<span class="hljs-number">0.5</span>)/N;<br>        subsum += <span class="hljs-number">4</span>/(<span class="hljs-number">1</span> + x*x);<br>      &#125;<br>  &#125;<br>  <span class="hljs-type">double</span> sum;<br>  MPI_Reduce(&amp;subsum, &amp;sum, <span class="hljs-number">1</span>, MPI_DOUBLE, MPI_SUM, <span class="hljs-number">0</span>, MPI_COMM_WORLD);<br>  <span class="hljs-keyword">if</span> (rank == <span class="hljs-number">0</span>)<br>     <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;pi = %.10lf\n&quot;</span>, sum*nthreads/N);<br>  MPI_Finalize();<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>当我们有线程时，考虑如何分割工作负载是很重要的。你可以通过下面这行看到工作负载是如何分割的，所以我们遵循MPI要求的相同原则。如果我们有n个线程，那么我们需要增加跳到下一个块的大小*nthreads的值。每个分块都是这样计算的。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = rank; i &lt; N; i += size*nthreads)<br></code></pre></td></tr></table></figure>

<p>subsum的收集，实际上是线程中的一个共享变量，对每个MPI进程来说，开始时是0.0，从每个线程的一个等级中收集，所以我们在OpenMP并行区域的最后得到每个MPI进程的subsum。之后，主线程将这个子和与MPI一起减少为总和。</p>
<p>我们在3个进程上编译并运行这个程序，通过在代码内设置2个线程，我们在3个等级（等级0、1和2）内总共有6个线程。</p>
<figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sas">mpicc -fopenmp pi-hybrid.c <span class="hljs-variable">&amp;&amp;</span> mpirun -n 3 --allow-run-<span class="hljs-keyword">as</span>-root a.<span class="hljs-keyword">out</span><br></code></pre></td></tr></table></figure>

<p>请看一下代码，并在本文末尾的笔记本中运行它。</p>
<h4 id="该练习的学习成果"><a href="#该练习的学习成果" class="headerlink" title="该练习的学习成果"></a>该练习的学习成果</h4><p>这个程序是以线程方法的第一种方式（MPI+OpenMP）完成的。</p>
<ul>
<li>我们刚才在笔记本例子中做的这种并行化方式很适合大多数OpenMP模型。</li>
<li>昂贵的循环是用OpenMP并行化的，这样做更快。你可以利用许多处理器的内核，所以线程的数量翻倍，而不是内核。所以，以这种方式运行程序肯定有一定的潜力。</li>
<li>循环之间的通信和MPI调用。</li>
<li>消除了对真正的 “线程安全 “MPI的需求。</li>
<li>并行扩展效率可能被MPI_THREAD_FUNNELED方法所限制（Amdahl’s law）。</li>
<li>迁移到MPI_THREAD_MULTIPLE确实需要付出性能代价（和编程挑战）。</li>
</ul>
<h3 id="三、Hybrid-MPI"><a href="#三、Hybrid-MPI" class="headerlink" title="三、Hybrid MPI"></a>三、Hybrid MPI</h3><p>混合MPI+OpenMP的Masteronly风格</p>
<p>我们在前面的练习中看到，扩展效率可能受到阿姆达尔定律的限制。当然，这意味着，即使所有的计算实际上都被并行化了，我们仍然可能有大块的串行代码存在。例如，串行代码就是前面例子中#pragma omp for reduction之后的代码。所以，还原子句是串行部分的代码，尽管它利用了并行线程。但这是最后一条命令，下面的MPI_Reduce实际上是集体通信，我们已经学过了。</p>
<p>如果我们在循环中做这样的事情，我们肯定会得到一定量的串行代码，这意味着我们无论如何都会受到阿姆达尔定律的限制。这直接意味着我们无法利用每天在新的和最近的硬件上涌现出来的丰富的数千个或更多的内核（甚至一百万个）。</p>
<p>解决这些问题的一个有效办法是重叠。某种区域，我们可以同时做MPI和OpenMP，以克服这些通信问题。这可以通过Hybrid MPI + OpenMP Masteronly Style来实现。使用这种混合方式有相当多的优点，然而，最突出的是：</p>
<ul>
<li>SMP节点内部没有信息传递，并且</li>
<li>不存在拓扑结构问题。</li>
</ul>
<p>一个有效的例子来解释其必要性和效率，比如说我们在一个房间里做光线追踪。光线追踪的问题是，我们所描述的体积是相当复杂的。因此，假设我们必须做光线追踪，以及我们从照明等方面看到的反射，我们将需要计算每条光线的参数。这已经是几GB的内存了，如果我们每个节点只有60GB的内存，那么我们解决这个问题就会受到内存的限制。所以，我们不能用许多核心来做大问题，因为MPI中的每个核心实际上都有自己的问题在里面。线程、进程或核心之间不存在问题的共享。我们通常可以通过使用MPI+OpenMP相当容易地解决这个问题。这类问题需要大量的内存，因为它们是复杂的，因为要描述环境等等，所以最好用MPI+OpenMP来解决。</p>
<h4 id="在OMP-MASTER中调用MPI"><a href="#在OMP-MASTER中调用MPI" class="headerlink" title="在OMP MASTER中调用MPI"></a>在OMP MASTER中调用MPI</h4><p>如果我们想做通信，那么通常最好是做OMP主线程。这可以确保只有一个线程与MPI进行通信。然而，我们仍然需要做一些同步工作。正如我们在前几周学到的关于同步的知识，在并行编程中，有时在处理多个并行运行的线程时，我们要暂停线程的执行，而在同一时间只运行一个线程。同步意味着每当我们做MPI时，所有的线程都需要在某个时刻停下来，做屏障。</p>
<p>在OpenMP中，MPI是在一个并行区域内调用的，有OMP MASTER。它需要MPI_THREAD_FUNNELED，我们在上一小节看到，这意味着只有主线程会进行MPI调用。然而，我们需要注意的是，OMP MASTER并没有任何的同步性！在OMP MASTER中没有隐含的屏障。在主工作共享结构中没有隐含的屏障。因此，使用OMP BARRIER有必要保证，在MPI调用之前&#x2F;之后，其他线程的数据或缓冲空间是可用的。屏障对于防止数据竞赛是必要的。</p>
<figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs objectivec"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp barrier</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp master</span><br>&#123;<br>    <span class="hljs-built_in">MPI_Xxx</span>(...);<br>&#125;<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp barrier</span><br></code></pre></td></tr></table></figure>

<p>我们可以看到，这意味着所有其他的线程都在睡觉，而额外的屏障意味着必要的缓存刷新！通过下面的练习，我们将看到为什么需要刷新缓存。<br>通过下面的练习，我们将看到为什么屏障是必要的。</p>
<h4 id="Example-with-MPI-recv"><a href="#Example-with-MPI-recv" class="headerlink" title="Example with MPI_recv"></a>Example with <code>MPI_recv</code></h4><p>在这个例子中，主线程将在OMP MASTER结构中执行一个MPI调用，而其他线程都是空闲的。如图所示，在两个地方可能需要屏障。</p>
<ul>
<li>在MPI调用之前，以防MPI调用需要等待其他线程的结果。</li>
<li>在MPI调用之后，以防其他线程立即需要MPI的结果</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp parallel</span><br>&#123;<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp for nowait</span><br>    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">1000</span>; i++)<br>        a[i] = buf[i];<br><br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp barrier</span><br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp master</span><br>    &#123;<br>        MPI_Recv(buf,....);<br>    &#125; <br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp barrier</span><br><br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp for nowait</span><br>    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">1000</span>; i++)<br>        c[i] = buf[i];<br>&#125;<br></code></pre></td></tr></table></figure>
                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/MPI/" class="category-chain-item">MPI</a>
  
  
    <span>></span>
    
  <a href="/categories/MPI/Introduction-to-Parallel-Programming/" class="category-chain-item">Introduction-to-Parallel-Programming</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/">#并行计算</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>MPI Continued</div>
      <div>http://by.ecel.top/MPI/Introduction-to-Parallel-Programming/MPI Continued/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>刘笑笑</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年12月10日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/Documentation/Linux/" title="Linux命令——查看cpu相关">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Linux命令——查看cpu相关</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/Documentation/ssh/" title="vscode 远程连接服务器">
                        <span class="hidden-mobile">vscode 远程连接服务器</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    

  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
